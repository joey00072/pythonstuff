---
title: NOV-24 Things I've Read
date: '2024-12-01'
tags: ['ML', 'papers', 'Machine Learning']
summary: short notes on things I've read
authors: ['default']
---

small notes on things I've read in november 2024


## Weights Don't Move
![Screenshot neural network weights](/static/images/weight_dont_move.png)

weights dont change form their inital configuration usually initized at random.
so if you put some image in weights of neural network and train it, you can still see that image.
this also mean neural network is not finding all possible configuration, only one close to initiliztion, so more advace optimization tequines can make better smaller netwroks,


but keep in mind, This where experiments on small model with relu activation and trained on mnist with sgd,
no adam, no weight decay so yet to see of this extrapolate to large networks

paper: https://arxiv.org/pdf/2012.02550


### Latent Preference Optimization (LPO)

![Screenshot of LPO architecture](/static/images/lpo.png)

<b>Problem:</b> Current LLM rely on fixed temperature decoding, we know high temperature is more creative and low temperature is more factual.
<b>Solution:</b> Have dynamic temperature based on context.

This is neat trick, they add another decoding head at end (dim, vocab_size), use it to predict temperature. 
Now we generate perference data with this dynamic temperature. tell ppl or model to rank it.
based on it we DPO finetune model. Loss of temperature head can be in same closed from as DPO,

$$
L_{\text{LPO}} = -\log \sigma \left[\beta \log P(\tau_c) - \beta \log P(\tau_r)\right]
$$
paper: https://arxiv.org/abs/2411.15124

### TÃ¼lu 3

![TULU3](/static/images/tulu3.png)

paper is nice and detailed, but open code make it delightful, 
- SFT performance varies based on the random seed
- Adding task specific pretraining data mix in SFT dataset improves performance
- Tulu 3 is a good example of how to use Tulu to fine tune LLM
- Chat template impacts performance
- Random seed affects performance of SFT :)
- Length normalized verient of DPO is best


## TODO Copy rest form obsiaion and push mf